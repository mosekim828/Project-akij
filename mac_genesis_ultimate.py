import os
import time
import json
import re
import subprocess
import glob
import shutil
import random
import requests
from datetime import datetime
from collections import Counter
from typing import List, Dict, TypedDict, Any, Tuple, Union
from mlx_lm import load, generate

# â˜… RAG ê²€ìƒ‰ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
try:
    from langchain_community.vectorstores import Chroma
    from langchain_community.embeddings import HuggingFaceEmbeddings
except ImportError:
    print("âš ï¸ [System] LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. 'pip install langchain-community chromadb' í•„ìš”.")

import fitz  # PyMuPDF

# ==============================================================================
# [0] í•µì‹¬ ì„¤ì • (USER CONFIGURATION)
# ==============================================================================

# 1. PC í™”ê°€ ì„œë²„ (ì œê³µí•´ì£¼ì‹  ì½”ë“œëŒ€ë¡œ 61ë²ˆìœ¼ë¡œ ìœ ì§€í•¨)
PC_FLUX_SERVER_URL = "http://192.168.0.61:8000/draw"

# 2. ê¸°ë³¸ ì‚½í™” ë¹ˆë„
DEFAULT_ILLUSTRATION_FREQ = 3 

# 3. ê²½ë¡œ ì„¤ì •
USER_HOME = "/Users/juson"
MODEL_PATH = f"{USER_HOME}/.cache/huggingface/hub/models--mlx-community--Llama-4-Maverick-17B-16E-Instruct-6bit/snapshots/542ea389fcd614c665c4306bd60ad053d9da8d03"

FACTORY_DIR = f"{USER_HOME}/Desktop/factory_input"
DIR_RESULT = os.path.join(FACTORY_DIR, "1_Result")
DIR_REFERENCE = os.path.join(FACTORY_DIR, "2_Reference_Style")

GENESIS_PATH = f"{USER_HOME}/Desktop/Genesis_Project"
DIR_TEMPLATE = os.path.join(GENESIS_PATH, "D0_template")
DIR_FONTS = os.path.join(GENESIS_PATH, "D5_Fonts")

# â˜… [V12] Vector DB ê²½ë¡œ & ì„ë² ë”© ëª¨ë¸ (Builderì™€ ì¼ì¹˜í•´ì•¼ í•¨)
DB_PERSIST_DIR = f"{USER_HOME}/Desktop/Genesis_Project/99_VectorDB"
EMBEDDING_MODEL_ID = "BAAI/bge-m3"

# 4. í°íŠ¸/ê¸°íƒ€
DEFAULT_FONT_TITLE = "AppleSDGothicNeo-Bold"
DEFAULT_FONT_BODY = "AppleMyungjo"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# 5. ë§ì¶¤ë²• ê²€ì‚¬ê¸°
try:
    from hanspell import spell_checker
    HANSPELL_AVAILABLE = True
except ImportError:
    HANSPELL_AVAILABLE = False
    print("âš ï¸ [System] py-hanspell ë¯¸ì„¤ì¹˜. AI êµì •ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")


# ==============================================================================
# [1] ë„êµ¬ í´ë˜ìŠ¤ (TOOLKIT - V12 RAG Integrated)
# ==============================================================================

class StyleReplicator:
    @staticmethod
    def analyze_pdf(pdf_path):
        try:
            doc = fitz.open(pdf_path)
            page = doc[0]
            blocks = page.get_text("dict")["blocks"]
            font_sizes = []
            for b in blocks:
                if "lines" in b:
                    for l in b["lines"]:
                        for s in l["spans"]:
                            font_sizes.append(s["size"])
            if not font_sizes: return None
            
            body_size = Counter(font_sizes).most_common(1)[0][0]
            title_size = max(font_sizes)
            rect = page.rect
            margin_x = (rect.width - (blocks[0]["bbox"][2] - blocks[0]["bbox"][0])) / 2 if blocks else 72
            
            return {
                "filename": os.path.basename(pdf_path),
                "page_width": rect.width, "page_height": rect.height,
                "body_size": f"{body_size:.1f}pt", "title_size": f"{title_size:.1f}pt",
                "margin": f"{margin_x / 2.83:.1f}mm"
            }
        except: return None

class TermGuard:
    CORRECTION_DICT = {
        "ë…¸ê°€": "ë…¸ì•„", "ë…¸ì•„ì˜ ë°©ì£¼": "ë…¸ì•„ì˜ ë°©ì£¼", 
        "ì—¬í˜¸ì™€": "ì—¬í˜¸ì™€", "ë‹¤ìœ—": "ë‹¤ìœ—", "ë°”ìš¸": "ë°”ìš¸",
        "ì„¸ì‹ ì": "ìƒˆì‹ ì", "ì„¸ë¡€êµì¸": "ì„¸ë¡€êµì¸",
        "ì˜ˆìˆ˜ë‹˜": "ì˜ˆìˆ˜ë‹˜", "í•˜ë‚˜ë‹˜": "í•˜ë‚˜ë‹˜",
        "ê·¸ë¦¬ìŠ¤ì¸": "ê·¸ë¦¬ìŠ¤ë„ì¸", "ê¸°ë¥¼ ì¶•ë³µí•©ë‹ˆë‹¤": "ì£¼ë‹˜ì˜ ì´ë¦„ìœ¼ë¡œ ì¶•ë³µí•©ë‹ˆë‹¤"
    }
    @staticmethod
    def enforce(text: str) -> str:
        for wrong, right in TermGuard.CORRECTION_DICT.items():
            if wrong in text: text = text.replace(wrong, right)
        text = text.replace("<", "").replace(">", "")
        text = re.sub(r"\n{3,}", "\n\n", text)
        return text

    @staticmethod
    def run_spell_check(text: str) -> str:
        if not HANSPELL_AVAILABLE: return text
        try:
            corrected = ""
            for line in text.split('\n'):
                if not line.strip(): corrected += "\n"
                elif len(line) < 500: corrected += spell_checker.check(line).checked + "\n"
                else: corrected += line + "\n"
            return corrected.strip()
        except: return text

class TextManager:
    @staticmethod
    def split_text_clean(text, chunk_size=3000):
        chunks = []
        start = 0
        text_len = len(text)
        while start < text_len:
            end = min(start + chunk_size, text_len)
            if end < text_len:
                last_period = text.rfind('.', start, end)
                if last_period != -1 and last_period > start + (chunk_size // 2): end = last_period + 1
            chunk = text[start:end].strip()
            if chunk: chunks.append(chunk)
            start = end
        return chunks

class KnowledgeManager:
    """
    [V12 Librarian] Vector DB ê²€ìƒ‰ ë° í°íŠ¸/í…œí”Œë¦¿ ê´€ë¦¬
    """
    @staticmethod
    def scan_fonts(font_dir):
        found = []
        if os.path.exists(font_dir):
            for root, _, files in os.walk(font_dir):
                for file in files:
                    if file.lower().endswith(('.ttf', '.otf')):
                        name = os.path.splitext(file)[0]
                        name = re.sub(r"-(Bold|Regular|Light|Medium|Black|Thin|ExtraBold|SemiBold)", "", name, flags=re.IGNORECASE)
                        name = re.sub(r"([a-z])([A-Z])", r"\1 \2", name) 
                        if "Noto Sans" in name: name = "Noto Sans KR"
                        if "Noto Serif" in name: name = "Noto Serif KR"
                        name = name.strip()
                        if name not in found: found.append(name)
        return found if found else [DEFAULT_FONT_TITLE, DEFAULT_FONT_BODY]

    @staticmethod
    def load_templates():
        """ë””ìì¸ í…œí”Œë¦¿ì€ DBê°€ ì•„ë‹Œ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (ì •í™•ì„±)"""
        buf = ""
        if os.path.exists(DIR_TEMPLATE):
            for file in glob.glob(os.path.join(DIR_TEMPLATE, "*.typ")):
                try: 
                    with open(file, 'r', encoding='utf-8') as f:
                        buf += f"\n[Template Code: {os.path.basename(file)}]\n{f.read()}\n"
                except: pass
        return buf

    @staticmethod
    def search_vector_db(query: str, k: int = 5) -> str:
        """
        â˜… [V12 RAG Core] Vector DBì—ì„œ ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰
        """
        if not os.path.exists(DB_PERSIST_DIR):
            log("Librarian", "âš ï¸ Vector DBê°€ ì—†ìŠµë‹ˆë‹¤. 'build_knowledge_base.py'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return ""

        log("Librarian", f"ğŸ” ì§€ì‹ ë„ì„œê´€ ê²€ìƒ‰ ì¤‘: '{query[:30]}...'")
        try:
            # ì„ë² ë”© ëª¨ë¸ (Mac mps ê°€ì†)
            embeddings = HuggingFaceEmbeddings(
                model_name=EMBEDDING_MODEL_ID,
                model_kwargs={'device': 'mps'},
                encode_kwargs={'normalize_embeddings': True}
            )
            # DB ì—°ê²°
            vectordb = Chroma(
                persist_directory=DB_PERSIST_DIR, 
                embedding_function=embeddings,
                collection_name="genesis_knowledge"
            )
            # ê²€ìƒ‰
            docs = vectordb.similarity_search(query, k=k)
            
            # ê²°ê³¼ ì •ë¦¬
            context_text = ""
            for i, doc in enumerate(docs):
                src = doc.metadata.get("source", "Unknown")
                cat = doc.metadata.get("category", "Unknown")
                context_text += f"\n[Reference {i+1} | {cat}/{src}]\n{doc.page_content}\n"
            
            log("Librarian", f"âœ… ê´€ë ¨ ë¬¸ì„œ {len(docs)}ê±´ í™•ë³´ ì™„ë£Œ.")
            return context_text
            
        except Exception as e:
            log("Librarian", f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return ""

    @staticmethod
    def fix_typst_syntax(code: str) -> str:
        """
        [V12.5 ìˆ˜ì •] Typst 0.11+ í˜¸í™˜ì„± íŒ¨ì¹˜ (loc -> context)
        íŠ¹íˆ 'unknown variable: loc' ì˜¤ë¥˜ë¥¼ ì¡ê¸° ìœ„í•´ query í•¨ìˆ˜ ë‚´ë¶€ë¥¼ ì •ë°€ íƒ€ê²©í•¨.
        """
        # 1. locate(loc => ...) íŒ¨í„´ì„ #contextë¡œ ë³€ê²½
        if "locate(" in code:
            log("System", "ğŸ› ï¸ Typst ë¬¸ë²• ìˆ˜ì„ : locate -> context")
            code = re.sub(r"#?locate\s*\(\s*\w+\s*=>", "#context", code) # locate(loc => ì§€ì›€
            code = code.replace("locate(loc =>", "#context") # í˜¹ì‹œ ëª°ë¼ ë‹¨ìˆœ ì¹˜í™˜ë„ ìœ ì§€

        # 2. [í•µì‹¬ ìˆ˜ì •] query í•¨ìˆ˜ ë‚´ë¶€ì— ìˆëŠ” ', loc' ì¸ìë¥¼ ì œê±°
        # ì˜ˆ: query(heading, loc) -> query(heading)
        # ì´ ë¶€ë¶„ì´ 'unknown variable: loc' ì—ëŸ¬ì˜ ì£¼ë²”ì„
        code = re.sub(r"query\(([^)]+),\s*loc\)", r"query(\1)", code)

        # 3. counter(page).at(loc) -> counter(page).get()
        code = code.replace(".at(loc)", ".get()")
        
        # 4. ë‹«íˆì§€ ì•Šì€ ê´„í˜¸ ì •ë¦¬
        open_sq = code.count('[')
        close_sq = code.count(']')
        if close_sq > open_sq:
            diff = close_sq - open_sq
            code = code[::-1].replace(']', '', diff)[::-1]
        return code

def log(agent, msg):
    icons = {"Director": "ğŸ¬", "Librarian": "ğŸ“š", "Editor": "âœï¸", "Designer": "ğŸ¨", "System": "âš™ï¸", "Replicator": "ğŸ§¬", "Illustrator": "ğŸ–Œï¸"}
    print(f"[{datetime.now().strftime('%H:%M:%S')}] {icons.get(agent, 'ğŸ¤–')} [{agent}] {msg}")

def cleanup_on_start():
    for d in [FACTORY_DIR, DIR_RESULT, DIR_REFERENCE, DIR_TEMPLATE]:
        if not os.path.exists(d): os.makedirs(d)
    target = os.path.join(FACTORY_DIR, "pc_output.json")
    if os.path.exists(target):
        try:
            timestamp = int(time.time())
            os.rename(target, os.path.join(FACTORY_DIR, f"ignored_{timestamp}.json"))
        except: pass

# ==============================================================================
# [2] ìƒíƒœ ê´€ë¦¬
# ==============================================================================
class BookState(TypedDict):
    user_instruction: str; raw_material: str; img_snap: str; img_flux: str
    learned_style: str; knowledge_context: str; available_fonts: List[str]
    book_title: str; text_chunks: List[str]
    polished_chunks: List[Tuple[str, str]]
    current_chunk_idx: int; layout_config: Dict[str, str]
    replicated_template_name: str; selected_style_name: str
    illustration_freq: int

# ==============================================================================
# [3] AI ì—ì´ì „íŠ¸
# ==============================================================================

def load_model_once():
    try:
        log("System", "Maverick(Llama-4) ì—”ì§„ ì˜ˆì—´ ì¤‘...")
        return load(MODEL_PATH)
    except: return None, None

def agent_librarian(model, tokenizer, state: BookState) -> BookState:
    """
    [V12 Librarian] RAG ê²€ìƒ‰ ì‹¤í–‰
    """
    log("Librarian", "ì§€ì‹ ë„ì„œê´€ ì ‘ì† ì¤‘...")
    state['available_fonts'] = KnowledgeManager.scan_fonts(DIR_FONTS)
    
    # 1. í…œí”Œë¦¿ ë¡œë“œ (ë””ìì¸ìš©)
    tpl_context = KnowledgeManager.load_templates()
    
    # 2. â˜… RAG ê²€ìƒ‰: ì‚¬ìš©ì ì§€ì‹œ + ì›ë¬¸ ì¼ë¶€ë¥¼ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
    search_query = f"{state['user_instruction']} {state['raw_material'][:500]}"
    retrieved_knowledge = KnowledgeManager.search_vector_db(search_query, k=6)
    
    # 3. ìµœì¢… ì»¨í…ìŠ¤íŠ¸ í•©ì²´
    state['knowledge_context'] = tpl_context + "\n" + retrieved_knowledge
    return state

def agent_replicator(model, tokenizer, state: BookState) -> BookState:
    state['replicated_template_name'] = ""
    state['selected_style_name'] = "Default"
    
    pdf_files = glob.glob(os.path.join(DIR_REFERENCE, "*.pdf"))
    if not pdf_files:
        log("Replicator", "âš ï¸ ìŠ¤íƒ€ì¼ ì°¸ê³ ìš© PDFê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©.")
        return state

    target_pdf = None
    instruction = state['user_instruction'].lower()
    for pdf in pdf_files:
        if os.path.splitext(os.path.basename(pdf))[0].lower() in instruction:
            target_pdf = pdf; break
    if not target_pdf: target_pdf = random.choice(pdf_files)
    
    state['selected_style_name'] = os.path.basename(target_pdf)
    analysis = StyleReplicator.analyze_pdf(target_pdf)
    
    if analysis:
        log("Replicator", f"ìŠ¤íƒ€ì¼ ë¶„ì„ ì™„ë£Œ: {analysis['filename']}")
        fonts_str = ", ".join(state['available_fonts'])
        
        prompt = f"""<|system|>Typst 0.11+ ë²„ì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ë°ì´í„°]: {analysis}
[í°íŠ¸]: {fonts_str}
[ì£¼ì˜]: Typst 0.11ë¶€í„° `locate` í•¨ìˆ˜ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ `context` í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
[ì§€ì‹œ]: ìœ„ í°íŠ¸ ì¤‘ ì ì ˆí•œ ê²ƒì„ ê³¨ë¼ ì‚¬ìš©í•˜ê³ , ì˜¤ì§ Typst ì½”ë“œë§Œ ì¶œë ¥.<|user|>ì‘ì„±<|assistant|>"""
        
        typ_code = generate(model, tokenizer, prompt=prompt, max_tokens=1500, verbose=False)
        typ_code = typ_code.replace("```typst", "").replace("```", "").strip()
        typ_code = KnowledgeManager.fix_typst_syntax(typ_code)
        
        template_name = f"replicated_{int(time.time())}.typ"
        with open(os.path.join(DIR_TEMPLATE, template_name), "w", encoding="utf-8") as f: f.write(typ_code)
        state['replicated_template_name'] = template_name

    return state

def agent_director(model, tokenizer, state: BookState) -> BookState:
    if not state['raw_material']: return state
    log("Director", "ê¸°íš ë° ì „ì²˜ë¦¬ ì¤‘...")
    
    prompt = f"""<|system|>ë² ìŠ¤íŠ¸ì…€ëŸ¬ ê¸°íšìì…ë‹ˆë‹¤. ì œëª© ê²°ì •. 'ì œëª©:' ì œê±°.
[ì§€ì‹œ]: "{state['user_instruction']}"
[ë‚´ìš©]: {state['raw_material'][:3000]}<|user|>ì œëª© ê²°ì •<|assistant|>"""
    
    title_raw = generate(model, tokenizer, prompt=prompt, max_tokens=60, verbose=False).strip()
    state['book_title'] = re.sub(r"^(ì œëª©|ì±…\s*ì œëª©|Title)\s*[:ï¼š]\s*", "", title_raw, flags=re.IGNORECASE).strip('"\' ')
    log("Director", f"ì±… ì œëª© í™•ì •: {state['book_title']}")
    
    state['text_chunks'] = TextManager.split_text_clean(state['raw_material'])
    return state

def agent_hybrid_editor(model, tokenizer, state: BookState) -> BookState:
    idx = state['current_chunk_idx']
    if idx >= len(state['text_chunks']): return state
    
    current_text = state['text_chunks'][idx]
    log("Editor", f"ìœ¤ë¬¸ ì‘ì—… ì¤‘... [{idx+1}/{len(state['text_chunks'])}]")
    
    prev_text = ""
    if state['polished_chunks']:
        for t, c in reversed(state['polished_chunks']):
            if t == 'text':
                prev_text = c[-300:]
                break
    
    # RAGë¡œ ê²€ìƒ‰ëœ ì§€ì‹ì€ modelì˜ system promptë‚˜ contextì— ìë™ í¬í•¨ë¨ (knowledge_context)
    prompt = f"""<|system|>ìˆ˜ì„ í¸ì§‘ì¥ì…ë‹ˆë‹¤. ë¬¸ë§¥ ë³µì› ë° ìœ¤ë¬¸.
[ì°¸ê³  ì§€ì‹]: {state['knowledge_context'][:2000]}
[ì›ì¹™] ë¬¸ë§¥ ë³µì›, ë¬¸ì–´ì²´, ë¬¸ë‹¨ êµ¬ë¶„.
<|user|>[ì´ì „]:...{prev_text}\n[ì›ë¬¸]:{current_text}\n[ì§€ì‹œ]:ìœ¤ë¬¸í•˜ë¼.<|assistant|>"""
    
    draft = generate(model, tokenizer, prompt=prompt, max_tokens=4000, verbose=False)
    draft = re.sub(r"^(ë„¤|ë¬¼ë¡ |ì•Œê² |í™•ì¸|ìˆ˜ì •|ìœ¤ë¬¸|ì œì‹œ|ë”°ë¼ì„œ).+?(\n|$)", "", draft, flags=re.MULTILINE).strip()
    
    if HANSPELL_AVAILABLE: 
        draft = TermGuard.run_spell_check(draft)
    
    final_text = TermGuard.enforce(draft)
    state['polished_chunks'].append(('text', final_text))
    state['current_chunk_idx'] += 1
    return state

def agent_illustrator(model, tokenizer, state: BookState) -> BookState:
    """
    â˜… [V12.4 ìµœì¢… ìˆ˜ì •] í•œê¸€ ì›ì²œ ë´‰ì‡„ & ì ê¼¬ëŒ€ ë°©ì§€
    """
    processed_count = len(state['polished_chunks'])
    if not state['polished_chunks']: return state

    last_type, last_content = state['polished_chunks'][-1]
    freq = state.get('illustration_freq', DEFAULT_ILLUSTRATION_FREQ)

    if last_type == 'text' and (processed_count % freq == 0):
        log("Illustrator", f"ğŸ¨ ë¬¸ë§¥ ë¶„ì„ ë° ì‚½í™” ì˜ë¢° (ì„¤ì • ë¹ˆë„: {freq})...")
        
        # 1. AIì—ê²Œ ì§€ì‹œ (ì˜ì–´ë§Œ ì“°ë¼ê³  ê°•ë ¥íˆ ìš”êµ¬)
        prompt_desc = f"""<|system|>You are a Visual Director.
Create a text-to-image prompt based on the context.
[Context]: {last_content[:500]}

[STRICT RULES]:
1. Output ONLY the raw English prompt.
2. DO NOT include introductory phrases.
3. ABSOLUTELY NO KOREAN.
4. Style: Biblical oil painting, solemn, cinematic lighting.
<|user|>Write prompt<|assistant|>"""
        
        # 2. ìƒì„± ì‹œë„ (ë§Œì•½ ëª¨ë¸ì´ ëœ ë¡œë”©ë˜ì—ˆìœ¼ë©´ ì—¬ê¸°ì„œ ë©ˆì¹«í•  ìˆ˜ ìˆìŒ)
        try:
            visual_prompt = generate(model, tokenizer, prompt=prompt_desc, max_tokens=150, verbose=False).strip()
        except Exception as e:
            log("Illustrator", f"âš ï¸ ëª¨ë¸ ìƒì„± ì˜¤ë¥˜: {e}")
            visual_prompt = "Error"

        # ======================================================================
        # â˜… [ì² í†µ ë³´ì•ˆ] í•œê¸€ ê°ì§€ ì‹œ ê°•ì œ êµì²´ (Iron Wall)
        # ======================================================================
        has_korean = bool(re.search(r'[ê°€-í£]', visual_prompt))
        is_too_long = len(visual_prompt) > 400
        is_error = "Error" in visual_prompt or not visual_prompt

        if has_korean or is_too_long or is_error:
            log("Illustrator", f"âš ï¸ [ì°¨ë‹¨] AIê°€ í•œê¸€/ì ê¼¬ëŒ€ë¥¼ í–ˆìŠµë‹ˆë‹¤. (ë‚´ìš©: {visual_prompt[:30]}...)")
            log("Illustrator", "ğŸ›¡ï¸ [ë°©ì–´] 'ê¸°ë³¸ ì•ˆì „ í”„ë¡¬í”„íŠ¸'ë¡œ ê°•ì œ êµì²´í•˜ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.")
            
            # ì•ˆì „í•œ ê¸°ë³¸ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë°”ê¿”ì¹˜ê¸°
            visual_prompt = "A holy biblical scene, oil painting style, cinematic lighting, solemn atmosphere, 8k resolution, detailed texture"
        
        # ì‚¬ì¡± ì œê±° (Here is... ë“±)
        visual_prompt = re.sub(r'^(Here is|Sure|Certainly|The prompt|Prompt:).*?[\:\n]', '', visual_prompt, flags=re.IGNORECASE | re.DOTALL).strip()
        
        log("Illustrator", f"ì˜ë¢°ì„œ ì „ì†¡(ìµœì¢…): {visual_prompt}")

        # 3. PCë¡œ ì „ì†¡
        try:
            res = requests.post(PC_FLUX_SERVER_URL, json={"prompt": visual_prompt}, timeout=60)
            if res.status_code == 200:
                fname = res.json().get("filename")
                if fname:
                    log("Illustrator", f"âœ… PC í™”ê°€ë¡œë¶€í„° ê·¸ë¦¼ ë„ì°©: {fname}")
                    state['polished_chunks'].append(('image', fname))
            else: 
                log("Illustrator", f"âš ï¸ PC ì„œë²„ ì˜¤ë¥˜: {res.status_code}")
        except Exception as e: 
            log("Illustrator", f"âŒ PC ì—°ê²° ì‹¤íŒ¨: {e}")
            
    return state

def agent_designer(model, tokenizer, state: BookState) -> bool:
    log("Designer", "ğŸ“š ìµœì¢… ì¡°íŒ ì‘ì—… ì‹œì‘ (í…ìŠ¤íŠ¸+ì‚½í™”).")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_file = os.path.join(DIR_RESULT, f"GenesisBook_{timestamp}")
    
    fonts = state['available_fonts']
    f_title = fonts[0] if fonts else DEFAULT_FONT_TITLE
    f_body = fonts[1] if len(fonts) > 1 else DEFAULT_FONT_BODY
    log("Designer", f"ì‚¬ìš© í°íŠ¸: ì œëª©='{f_title}', ë³¸ë¬¸='{f_body}'")

    body_code = ""
    for c_type, content in state['polished_chunks']:
        if c_type == 'text':
            clean = content
            for char in ["*", "_", "`", "$", "#", "[", "]", "<", ">", "@"]:
                clean = clean.replace(char, "\\" + char)
            body_code += f"{clean}\n\n"
            
        elif c_type == 'image':
            full_img_path = os.path.join(FACTORY_DIR, content)
            if os.path.exists(full_img_path):
                body_code += f"#v(1em)\n#figure(image(\"../{content}\", width: 90%), gap: 0.5em)\n#v(1em)\n\n"
            else:
                log("Designer", f"âš ï¸ ì´ë¯¸ì§€ íŒŒì¼ ëˆ„ë½ë¨ (ê±´ë„ˆëœ€): {content}")

    target_tpl = state.get('replicated_template_name', "")
    ref_code = ""
    if target_tpl:
        marker = f"[Template Code: {target_tpl}]"
        idx = state['knowledge_context'].find(marker)
        if idx != -1: ref_code = state['knowledge_context'][idx:idx+8000]
    
    # í…œí”Œë¦¿ ì½”ë“œ ëª» ì°¾ìœ¼ë©´ ê²€ìƒ‰ëœ ì§€ì‹ ì¼ë¶€ ì‚¬ìš©
    if not ref_code: ref_code = state['knowledge_context'][:5000]

    prompt = f"""<|system|>Typst 0.11+ ë²„ì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
[ì°¸ê³  í…œí”Œë¦¿]: {ref_code}
[ì •ë³´]: ì œëª©="{state['book_title']}", í°íŠ¸="{f_title}"
[ì£¼ì˜]: Typst 0.11+ ë¬¸ë²•ì„ ì—„ìˆ˜í•˜ì‹­ì‹œì˜¤. 'locate(loc => ...)' ëŒ€ì‹  'context'ë¥¼ ì‚¬ìš©í•˜ê³ , query í•¨ìˆ˜ì— 'loc' ì¸ìë¥¼ ë„£ì§€ ë§ˆì‹­ì‹œì˜¤.
[ì§€ì‹œ]: í‘œì§€ì™€ ëª©ì°¨ ì½”ë“œë§Œ ì‘ì„±. ì˜¤ì§ Typst ì½”ë“œë§Œ ì¶œë ¥.<|user|>ì‘ì„±<|assistant|>"""

    gen_code = generate(model, tokenizer, prompt=prompt, max_tokens=2000, verbose=False)
    gen_code = gen_code.replace("```typst", "").replace("```", "").strip()
    
    # [V12.5] ë¬¸ë²• ìˆ˜ì„  ë° ê´„í˜¸ ì •ë¦¬
    gen_code = KnowledgeManager.fix_typst_syntax(gen_code)

    full_typst = f"""
    // Genesis V12 RAG Ultimate Edition
    #set text(font: "{f_body}", size: 10.5pt, lang: "ko")
    
    {gen_code}
    
    #pagebreak()
    {body_code}
    """
    
    with open(f"{out_file}.typ", "w", encoding="utf-8") as f: f.write(full_typst)
    try:
        subprocess.run(["typst", "compile", f"{out_file}.typ", f"{out_file}.pdf", "--root", FACTORY_DIR, "--font-path", DIR_FONTS], check=True)
        log("Designer", f"ğŸ‰ ì„±ê³µ: {os.path.basename(out_file)}.pdf")
        return True
    except Exception as e:
        log("Designer", f"âŒ ì‹¤íŒ¨: {e}")
        return False

# ==============================================================================
# [5] ë©”ì¸ ë£¨í”„ (V11 ì›Œí¬í”Œë¡œìš°)
# ==============================================================================
def run_genesis_architect(model, tokenizer, input_json):
    # [V11.7] ë¹ˆë„ ì¶”ì¶œ
    custom_freq = DEFAULT_ILLUSTRATION_FREQ
    if "frequency" in input_json:
        try: custom_freq = int(input_json["frequency"])
        except: pass
    else:
        script_text = input_json.get("script", "")
        match = re.search(r"(?:ë¹ˆë„|frequency|freq)\s*[:=]\s*(\d+)", script_text, flags=re.IGNORECASE)
        if match:
            custom_freq = int(match.group(1))
            log("System", f"ğŸ“‹ ì‘ì—…ì§€ì‹œì„œì—ì„œ ì‚½í™” ë¹ˆë„ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤: {custom_freq}")

    state: BookState = {
        "user_instruction": input_json.get("script", ""), 
        "raw_material": input_json.get("script_ko", ""),  
        "img_snap": input_json.get("image_source", ""),
        "img_flux": input_json.get("flux_source", ""),
        "learned_style": "", "knowledge_context": "", "available_fonts": [],
        "book_title": "", "text_chunks": [], "polished_chunks": [],
        "current_chunk_idx": 0, "layout_config": {}, 
        "replicated_template_name": "", "selected_style_name": "",
        "illustration_freq": custom_freq
    }
    
    # 1. ê¸°íš ë‹¨ê³„ (Librarianì´ RAG ê²€ìƒ‰ ìˆ˜í–‰)
    state = agent_librarian(model, tokenizer, state) 
    state = agent_replicator(model, tokenizer, state)
    state = agent_director(model, tokenizer, state)
    
    # 2. ì œì‘ ë£¨í”„
    total = len(state['text_chunks'])
    while state['current_chunk_idx'] < total:
        state = agent_hybrid_editor(model, tokenizer, state)
        state = agent_illustrator(model, tokenizer, state)
    
    # 3. ìµœì¢… ì¡°íŒ
    return agent_designer(model, tokenizer, state)

def main():
    print("\n" + "="*80)
    print(" ğŸ›ï¸  [GENESIS WRITER V12.4: FINAL SAFETY]")
    print("     Prompt Guard Activated (Anti-Parrot)")
    print(f"     Monitoring: {FACTORY_DIR}")
    print("="*80)
    
    model, tokenizer = load_model_once()
    if not model: return
    cleanup_on_start()
    
    while True:
        try: _ = os.listdir(FACTORY_DIR)
        except: pass
        target = os.path.join(FACTORY_DIR, "pc_output.json")
        if os.path.exists(target):
            time.sleep(1)
            try:
                with open(target, 'r') as f: data = json.load(f)
                log("System", "ğŸš€ ì‘ì—… ì‹œì‘.")
                if run_genesis_architect(model, tokenizer, data):
                    os.rename(target, os.path.join(FACTORY_DIR, f"done_{int(time.time())}.json"))
                else: os.rename(target, os.path.join(FACTORY_DIR, target + ".err"))
            except Exception as e:
                log("System", f"âš ï¸ ì˜¤ë¥˜: {e}")
                if os.path.exists(target): os.rename(target, target + ".err")
        time.sleep(1)

if __name__ == "__main__":
    main()
