# íŒŒì¼ëª…: flux_server.py
# ìœ„ì¹˜: HP Omenì˜ Genesis_Factory í´ë” ì•ˆ

import os
import torch
from fastapi import FastAPI
from pydantic import BaseModel
from diffusers import FluxPipeline

# ==========================================
# 1. ì €ì¥ ê²½ë¡œ ì„¤ì • (Windows í™˜ê²½)
# ==========================================
# í˜„ì¬ íŒŒì¼ì´ ìˆëŠ” í´ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ '2_assets' í´ë”ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ASSET_DIR = os.path.join(BASE_DIR, "2_assets")

# í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
os.makedirs(ASSET_DIR, exist_ok=True)

# ==========================================
# 2. Flux 2.0 ëª¨ë¸ ë¡œë“œ (RTX 5090 íŒŒì›Œ ì‚¬ìš©)
# ==========================================
print("ğŸš€ [System] Flux 2.0 ëª¨ë¸ì„ RTX 5090 ë©”ëª¨ë¦¬ì— ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë¦¬ì„¸ìš”)")

# HuggingFaceì—ì„œ Flux ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œí•©ë‹ˆë‹¤.
# ì£¼ì˜: ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª‡ GB ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ëŠë¼ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤.
pipe = FluxPipeline.from_pretrained(
    "black-forest-labs/FLUX.1-dev",  # í˜¹ì€ "black-forest-labs/FLUX.1-schnell" (ë” ë¹ ë¦„)
    torch_dtype=torch.bfloat16
)

# GPU í• ë‹¹ (RTX 5090ì˜ VRAM í™œìš© ìµœì í™”)
pipe.enable_model_cpu_offload() 
# pipe.to("cuda") # ë§Œì•½ ìœ„ ì½”ë“œë¡œ ëŠë¦¬ë‹¤ë©´ ì´ ì¤„ì˜ ì£¼ì„ì„ í’€ê³  ìœ„ë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ì„¸ìš”.

print("âœ… [System] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! ê·¸ë¦¼ ê·¸ë¦´ ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ==========================================
# 3. ì„œë²„ ì„¤ì • (Macì˜ ìš”ì²­ì„ ë°›ëŠ” ê³³)
# ==========================================
app = FastAPI()

# ìš”ì²­ë°›ì„ ë°ì´í„° í˜•ì‹ ì •ì˜ (í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ëª…)
class ImageRequest(BaseModel):
    prompt: str
    filename: str

@app.post("/generate")
def generate_image(request: ImageRequest):
    print(f"\nğŸ“© [Request Received] Macì—ì„œ ìš”ì²­ ë„ì°©!")
    print(f" - í”„ë¡¬í”„íŠ¸: {request.prompt}")
    print(f" - íŒŒì¼ëª…: {request.filename}")

    # ì €ì¥ë  ì „ì²´ ê²½ë¡œ ë§Œë“¤ê¸°
    save_path = os.path.join(ASSET_DIR, request.filename)

    # ì´ë¯¸ ê°™ì€ íŒŒì¼ì´ ìˆìœ¼ë©´ ìŠ¤í‚µ (ì‹œê°„ ì ˆì•½)
    if os.path.exists(save_path):
        print(f"âš ï¸ [Skip] ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {save_path}")
        return {"status": "exists", "path": save_path}

    # === Fluxê°€ ê·¸ë¦¼ ê·¸ë¦¬ëŠ” í•µì‹¬ êµ¬ê°„ ===
    print("ğŸ¨ [Flux] ê·¸ë¦¼ ê·¸ë¦¬ëŠ” ì¤‘...", end="")
    
    image = pipe(
        request.prompt,
        height=1024,
        width=1024,
        guidance_scale=3.5,
        num_inference_steps=20, # í€„ë¦¬í‹°ê°€ ë‚®ìœ¼ë©´ 30~50ìœ¼ë¡œ ì˜¬ë¦¬ì„¸ìš”
        max_sequence_length=512,
        generator=torch.Generator("cpu").manual_seed(42) # ì‹œë“œ ê³ ì • (ì¼ê´€ì„± ìœ ì§€ìš©)
    ).images[0]
    
    # ì´ë¯¸ì§€ ì €ì¥
    image.save(save_path)
    print(f" ì™„ë£Œ! -> ì €ì¥ë¨: {save_path}")

    return {"status": "success", "path": save_path}

# ì‹¤í–‰ì€ í„°ë¯¸ë„ì—ì„œ: uvicorn flux_server:app --host 0.0.0.0 --port 8000
